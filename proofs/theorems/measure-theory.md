# Measure-Theoretic Foundations of Betlang

## Abstract

This document provides the rigorous measure-theoretic foundations underlying betlang's probability theory. We develop the theory from σ-algebras through the Lebesgue integral, establishing the mathematical framework for both discrete and continuous probability in probabilistic programming.

---

## 1. Measurable Spaces

### 1.1 σ-Algebra

**Definition 1.1** (σ-Algebra). A σ-algebra F on set Ω is a collection of subsets satisfying:
1. Ω ∈ F
2. A ∈ F ⟹ Aᶜ ∈ F (closure under complement)
3. A₁, A₂, ... ∈ F ⟹ ∪ᵢAᵢ ∈ F (closure under countable union)

**Definition 1.2** (Measurable Space). A measurable space is a pair (Ω, F).

### 1.2 Ternary Measurable Space

**Definition 1.3** (Ternary Space). For `(bet A B C)`:
$$Ω = \{A, B, C\}$$
$$\mathcal{F} = \mathcal{P}(Ω) = 2^Ω$$

This is the discrete σ-algebra (power set).

**Properties**:
- |F| = 2³ = 8
- Every subset is measurable
- Generated by singletons: F = σ({A}, {B}, {C})

### 1.3 Product σ-Algebra

**Definition 1.4** (Product Space). For spaces (Ω₁, F₁) and (Ω₂, F₂):
$$Ω_1 × Ω_2, \quad \mathcal{F}_1 ⊗ \mathcal{F}_2 = σ(\{A × B : A ∈ \mathcal{F}_1, B ∈ \mathcal{F}_2\})$$

**Application**: Joint distribution of independent bets.

---

## 2. Measure Theory

### 2.1 Measure

**Definition 2.1** (Measure). A measure μ on (Ω, F) is a function μ: F → [0, ∞] satisfying:
1. μ(∅) = 0
2. Countable additivity: For disjoint Aᵢ: μ(∪ᵢAᵢ) = Σᵢμ(Aᵢ)

**Definition 2.2** (Probability Measure). A probability measure P satisfies P(Ω) = 1.

### 2.2 Ternary Probability Measure

**Definition 2.3** (Uniform Ternary Measure). For (Ω, F) with Ω = {A, B, C}:
$$P(\{x\}) = \frac{1}{3} \quad ∀x ∈ Ω$$

**Theorem 2.1** (Kolmogorov Axioms). This measure satisfies:
1. P(E) ≥ 0 for all E ∈ F
2. P(Ω) = 1
3. For disjoint E₁, E₂, ...: P(∪ᵢEᵢ) = Σᵢ P(Eᵢ)

*Proof*:
1. Sum of non-negative terms is non-negative
2. P(Ω) = P({A}) + P({B}) + P({C}) = 1/3 + 1/3 + 1/3 = 1
3. For finite case in discrete space, follows from definition ∎

### 2.3 Weighted Measure

**Definition 2.4** (Weighted Ternary Measure). For weights w = (wₐ, w_b, w_c):
$$P(\{x\}) = \frac{w_x}{\sum_y w_y}$$

**Theorem 2.2** (Well-Defined Measure). This defines a probability measure iff:
1. wₓ ≥ 0 for all x
2. Σₓwₓ > 0

---

## 3. Random Variables

### 3.1 Definition

**Definition 3.1** (Random Variable). A random variable X on (Ω, F, P) is a measurable function:
$$X: Ω → E$$

where (E, ε) is a measurable space, and X⁻¹(B) ∈ F for all B ∈ ε.

### 3.2 Bet as Random Variable

**Definition 3.2** (Bet Random Variable). For `(bet A B C)`:
$$X: Ω → E$$
$$X(ω) = ω$$

where E = {A, B, C} with discrete σ-algebra.

### 3.3 Distribution

**Definition 3.3** (Distribution/Law). The distribution of X is the pushforward measure:
$$P_X(B) = P(X^{-1}(B)) = P(\{ω : X(ω) ∈ B\})$$

For uniform bet: Pₓ = Uniform({A, B, C}).

### 3.4 Measurability of Compositions

**Theorem 3.1** (Composition Measurability). If X is measurable and f is measurable, then f ∘ X is measurable.

*Proof*:
$$(f ∘ X)^{-1}(B) = X^{-1}(f^{-1}(B)) ∈ \mathcal{F}$$

since f⁻¹(B) ∈ ε and X is measurable. ∎

**Application**: `bet-map` preserves measurability.

---

## 4. Integration

### 4.1 Simple Functions

**Definition 4.1** (Simple Function). A simple function is:
$$s = \sum_{i=1}^n a_i \mathbf{1}_{A_i}$$

where 1_{Aᵢ} is the indicator function.

**Definition 4.2** (Integral of Simple Function).
$$\int s \, dP = \sum_{i=1}^n a_i P(A_i)$$

### 4.2 Lebesgue Integral

**Definition 4.3** (Lebesgue Integral). For non-negative measurable f:
$$\int f \, dP = \sup\left\{\int s \, dP : s \text{ simple}, s ≤ f\right\}$$

For general f: ∫f dP = ∫f⁺ dP - ∫f⁻ dP where f = f⁺ - f⁻.

### 4.3 Expectation

**Definition 4.4** (Expectation).
$$\mathbb{E}[X] = \int_Ω X(ω) \, dP(ω)$$

**Theorem 4.1** (Ternary Expectation). For uniform `(bet A B C)` with numeric outcomes:
$$\mathbb{E}[X] = \frac{A + B + C}{3}$$

*Proof*:
$$\mathbb{E}[X] = \sum_{x ∈ Ω} x · P(\{x\}) = A · \frac{1}{3} + B · \frac{1}{3} + C · \frac{1}{3} = \frac{A+B+C}{3} ∎$$

### 4.4 Properties of Integration

**Theorem 4.2** (Linearity).
$$\mathbb{E}[aX + bY] = a\mathbb{E}[X] + b\mathbb{E}[Y]$$

**Theorem 4.3** (Monotone Convergence). If 0 ≤ Xₙ ↑ X:
$$\mathbb{E}[X_n] ↑ \mathbb{E}[X]$$

**Theorem 4.4** (Dominated Convergence). If Xₙ → X and |Xₙ| ≤ Y with E[Y] < ∞:
$$\mathbb{E}[X_n] → \mathbb{E}[X]$$

---

## 5. Product Measures

### 5.1 Definition

**Definition 5.1** (Product Measure). For (Ω₁, F₁, P₁) and (Ω₂, F₂, P₂):
$$(P_1 × P_2)(A × B) = P_1(A) · P_2(B)$$

Extended to F₁ ⊗ F₂ by Carathéodory.

### 5.2 Independence

**Definition 5.2** (Independence). X and Y are independent if:
$$P(X ∈ A, Y ∈ B) = P(X ∈ A) · P(Y ∈ B)$$

for all measurable A, B.

**Theorem 5.1** (bet-parallel Independence). In `(bet-parallel n A B C)`, the n trials are independent.

*Proof*: Each trial samples independently from the probability space. ∎

### 5.3 Fubini's Theorem

**Theorem 5.2** (Fubini). For integrable f on product space:
$$\int_{Ω_1 × Ω_2} f \, d(P_1 × P_2) = \int_{Ω_1} \left(\int_{Ω_2} f(x,y) \, dP_2(y)\right) dP_1(x)$$

**Application**: Computing expectations of functions of independent bets.

---

## 6. Conditional Probability

### 6.1 Definition

**Definition 6.1** (Conditional Probability).
$$P(A | B) = \frac{P(A ∩ B)}{P(B)}$$

for P(B) > 0.

### 6.2 Conditional Expectation

**Definition 6.2** (Conditional Expectation). E[X | G] for sub-σ-algebra G is the G-measurable random variable satisfying:
$$\int_A \mathbb{E}[X | \mathcal{G}] \, dP = \int_A X \, dP \quad ∀A ∈ \mathcal{G}$$

### 6.3 Properties

**Theorem 6.1** (Tower Property).
$$\mathbb{E}[\mathbb{E}[X | \mathcal{G}]] = \mathbb{E}[X]$$

**Theorem 6.2** (Independence). If X ⊥ G:
$$\mathbb{E}[X | \mathcal{G}] = \mathbb{E}[X]$$

---

## 7. Characteristic Functions

### 7.1 Definition

**Definition 7.1** (Characteristic Function).
$$\phi_X(t) = \mathbb{E}[e^{itX}]$$

### 7.2 Ternary Characteristic Function

**Theorem 7.1** (Uniform Ternary CF). For uniform bet on {-1, 0, 1}:
$$\phi_X(t) = \frac{1}{3}(e^{-it} + 1 + e^{it}) = \frac{1 + 2\cos(t)}{3}$$

### 7.3 Uniqueness

**Theorem 7.2** (Uniqueness). The characteristic function uniquely determines the distribution.

---

## 8. Convergence

### 8.1 Types of Convergence

**Definition 8.1** (Convergence Types).
1. **Almost sure**: P(Xₙ → X) = 1
2. **In probability**: ∀ε > 0: P(|Xₙ - X| > ε) → 0
3. **In distribution**: E[f(Xₙ)] → E[f(X)] for bounded continuous f
4. **In Lᵖ**: E[|Xₙ - X|ᵖ] → 0

### 8.2 Relationships

**Theorem 8.1** (Convergence Hierarchy).
$$\text{a.s.} ⟹ \text{in prob.} ⟹ \text{in dist.}$$
$$L^p ⟹ \text{in prob.} \text{ (for } p ≥ 1\text{)}$$

### 8.3 SLLN (Measure-Theoretic)

**Theorem 8.2** (Strong Law). For i.i.d. Xᵢ with E[|X|] < ∞:
$$\frac{1}{n}\sum_{i=1}^n X_i \xrightarrow{a.s.} \mathbb{E}[X]$$

*Proof*: By Kolmogorov's strong law using truncation and Borel-Cantelli. ∎

---

## 9. Radon-Nikodym Theorem

### 9.1 Absolute Continuity

**Definition 9.1** (Absolute Continuity). μ ≪ ν if ν(A) = 0 ⟹ μ(A) = 0.

### 9.2 Radon-Nikodym Derivative

**Theorem 9.1** (Radon-Nikodym). If μ ≪ ν for σ-finite measures, ∃ measurable f ≥ 0:
$$μ(A) = \int_A f \, dν$$

f is the Radon-Nikodym derivative dμ/dν.

### 9.3 Application: Importance Sampling

For target P and proposal Q with P ≪ Q:
$$\frac{dP}{dQ}(x) = \frac{p(x)}{q(x)}$$

is the importance weight.

---

## 10. Probability Kernels

### 10.1 Definition

**Definition 10.1** (Markov Kernel). A Markov kernel from (Ω₁, F₁) to (Ω₂, F₂) is:
$$K: Ω_1 × \mathcal{F}_2 → [0, 1]$$

such that:
1. K(ω, ·) is a probability measure for each ω
2. K(·, B) is measurable for each B

### 10.2 Composition

**Definition 10.2** (Kernel Composition).
$$(K_1 K_2)(x, C) = \int K_1(x, dy) K_2(y, C)$$

### 10.3 Betlang Stochastic Functions

**Theorem 10.1**. A betlang function f: A → Dist(B) is a Markov kernel from (A, P(A)) to (B, P(B)).

---

## 11. Polish Spaces and Regular Conditional Distributions

### 11.1 Polish Space

**Definition 11.1** (Polish Space). A topological space that is:
- Separable (has countable dense subset)
- Completely metrizable

### 11.2 Regular Conditional Distribution

**Theorem 11.1** (Existence). On Polish spaces, regular conditional distributions exist.

For random variable X and σ-algebra G, there exists kernel P^X|G such that:
$$P^{X|\mathcal{G}}(ω, B) = P(X ∈ B | \mathcal{G})(ω) \text{ a.s.}$$

---

## 12. Giry Monad (Measure-Theoretic)

### 12.1 Definition

**Definition 12.1** (Giry Monad on Meas).
- Objects: Measurable spaces (X, Σ)
- G(X) = probability measures on X with weak topology
- η_X: x ↦ δ_x (Dirac)
- μ_X: ∫ P dΦ for Φ ∈ G(G(X))

### 12.2 Relationship to Betlang

**Theorem 12.1**. The discrete Dist functor is the restriction of Giry to finite discrete spaces with counting measure.

---

## 13. Continuous Distributions in Betlang

### 13.1 Lebesgue Measure

**Definition 13.1** (Lebesgue Measure). On (ℝ, B(ℝ)):
$$λ([a, b]) = b - a$$

Extended to Borel σ-algebra.

### 13.2 Density

**Definition 13.2** (Probability Density). f is a density for P w.r.t. λ if:
$$P(A) = \int_A f(x) \, dλ(x)$$

### 13.3 Betlang Continuous Distributions

**Normal**:
$$f(x) = \frac{1}{\sqrt{2πσ^2}} \exp\left(-\frac{(x-μ)^2}{2σ^2}\right)$$

**Exponential**:
$$f(x) = λ e^{-λx} \mathbf{1}_{x ≥ 0}$$

---

## 14. Martingales

### 14.1 Definition

**Definition 14.1** (Martingale). A sequence (Xₙ, Fₙ) is a martingale if:
1. Xₙ is Fₙ-measurable
2. E[|Xₙ|] < ∞
3. E[Xₙ₊₁ | Fₙ] = Xₙ a.s.

### 14.2 Optional Stopping

**Theorem 14.1** (Optional Stopping). For bounded stopping time τ:
$$\mathbb{E}[X_τ] = \mathbb{E}[X_0]$$

### 14.3 Application: bet-until Analysis

For centered bet-until sum Sₙ = Σ(Xᵢ - E[Xᵢ]):
- (Sₙ, Fₙ) is a martingale
- Optional stopping applies to analyze hitting times

---

## 15. Weak Convergence

### 15.1 Definition

**Definition 15.1** (Weak Convergence). Pₙ ⇒ P if:
$$\int f \, dP_n → \int f \, dP$$

for all bounded continuous f.

### 15.2 Portmanteau Theorem

**Theorem 15.1** (Portmanteau). TFAE:
1. Pₙ ⇒ P
2. ∫f dPₙ → ∫f dP for bounded Lipschitz f
3. lim sup Pₙ(F) ≤ P(F) for closed F
4. lim inf Pₙ(G) ≥ P(G) for open G

### 15.3 Prokhorov's Theorem

**Theorem 15.2** (Prokhorov). On Polish spaces, tightness ⟺ relative compactness in weak topology.

---

## 16. Summary: Measure Theory in Betlang

| Concept | Betlang Realization |
|---------|---------------------|
| σ-algebra | Power set (discrete) |
| Measure | Probability distribution |
| Random variable | bet expression |
| Integration | Expectation (bet-expect) |
| Product measure | Independent bets |
| Kernel | Stochastic function |
| Density | PDF for continuous distributions |

---

## 17. TODOs

**TODO**: The following need measure-theoretic development:

1. **Disintegration theorem**: For conditional distributions
2. **Prokhorov metric**: For convergence of distributions
3. **Central limit theorem**: Measure-theoretic proof
4. **Ergodic theory**: For MCMC convergence
5. **Optimal transport**: Wasserstein distances

---

## References

1. Billingsley, P. (1995). *Probability and Measure*, 3rd ed.
2. Durrett, R. (2019). *Probability: Theory and Examples*, 5th ed.
3. Klenke, A. (2014). *Probability Theory: A Comprehensive Course*, 2nd ed.
4. Williams, D. (1991). *Probability with Martingales*
5. Giry, M. (1982). "A categorical approach to probability theory"
